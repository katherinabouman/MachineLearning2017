{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:left;margin:5px 10px 5px 10px\" markdown=\"1\">\n",
    "    <img src=\"images/auc.png\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "<div style=\"float:right;margin-top:10px\" markdown=\"1\">\n",
    "    <h3><i>Text Mining & Collective Intelligence</i></h3>\n",
    "</div>\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "<center><h1>Making Recommendations</h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "<h3>by Gianluca E. Lebani</h3>\n",
    "<h4>• 03 Nov. 2017 •</h4>\n",
    "\n",
    "</center>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Today\n",
    ">\n",
    ">- [the MovieLens 1M Dataset](#the-MovieLens-1M-Dataset)\n",
    ">\n",
    ">\n",
    ">- [Similarity Measures](#Similarity-Measures)\n",
    ">\n",
    ">\n",
    ">- [user-to-user kNN](#user-to-user-kNN)\n",
    ">\n",
    ">\n",
    ">- [item-to-item kNN](#item-to-item-kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import math\n",
    "\n",
    "from itertools import product, combinations\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the MovieLens 1M Dataset\n",
    "\n",
    "The MovieLens 1M dataset has been developed by the members of the [GroupLens](https://grouplens.org/) lab in the Department of Computer Science and Engineering at the University of Minnesota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MovieLens 1M dataset in brief:\n",
    "\n",
    "- Ratings: 1 million\n",
    "- Users: 6040\n",
    "- Rated Movies: 3592\n",
    "- Rated Scale: {1, ... , 5}\n",
    "- Additional information on the users: gender, age range, occupation, zip-code\n",
    "- Additional infomation on the movies: genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A zipped version of this dataset should be available in the `./data` folder, in case not [download it](https://grouplens.org/datasets/movielens/1m/) and unzip it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is composed by three files:\n",
    "\n",
    "- `movies.dat`, providing information about the rated movies \n",
    "    - it follows the format `MovieID::Title::Genres`\n",
    "    \n",
    "\n",
    "- `users.dat`, providing information about the users\n",
    "    - it follows the format `UserID::Gender::Age::Occupation::Zip-code`\n",
    "    - each user has at least 20 ratings\n",
    "\n",
    "\n",
    "- `ratings.dat`, encoding the ratings\n",
    "    - it follows the format `UserID::MovieID::Rating::Timestamp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2movie = dict()\n",
    "\n",
    "with open(\"data/ml-1m/movies.dat\", \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        movieId, movie, _ = line.split(\"::\")\n",
    "        id2movie[int(movieId)] = movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user2movies_ratings = defaultdict(dict)\n",
    "\n",
    "with open(\"data/ml-1m/ratings.dat\", \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        userId, movieId, rating = [int(el) for el in line.split(\"::\")[:3]]\n",
    "        user2movies_ratings[userId][movieId] = rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:left;margin:0 25px 10px 20px\">\n",
    "    <img src=\"images/your_turn.jpg\" width=\"110\">\n",
    "</div>\n",
    "\n",
    "#### Your Turn.\n",
    "\n",
    "Explore the dataset:\n",
    "\n",
    "- what is the average rating?\n",
    "\n",
    "\n",
    "- which are the top-rated movies? And which are the lowest-rated ones?\n",
    "\n",
    "\n",
    "- what are the average ratings for men and women?\n",
    "\n",
    "\n",
    "- which movies received the highest rates from men? Which ones from women?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-62c5572f19ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muser2movies_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "for user, subdicteroy in user2movies_ratings_iteritems():\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case\n",
    "\n",
    "In the following exercise we will use the **k Nearest Neighbors algorithm** (kNN)\n",
    "\n",
    "- the most popular algorithm in the first RSs\n",
    "\n",
    "\n",
    "- still the most-used algorithm for the collaborative filtering RSs\n",
    "\n",
    "\n",
    "- conceptually simple and easy to implement\n",
    "\n",
    "\n",
    "- it generally produces good predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODAY'S EXERCISE: \n",
    "\n",
    "- to model the ratings given by subject  `4447`...\n",
    "    - he gave 982 ratings\n",
    "\n",
    "\n",
    "- ... for the following movies:\n",
    "\n",
    "    - `Back to the Future (1985)`: id = `1270`\n",
    "    - `Silence of the Lambs, The (1991)` : id = `593`\n",
    "    - `Raiders of the Lost Ark (1981)` : id = `1198`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_movies = [593, 1198, 1270]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's remove our target ratings from the dataset\n",
    "\n",
    "target_ratings = dict([(i, user2movies_ratings[4447].pop(i)) for i in target_movies])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Measures\n",
    "\n",
    "Similarity/Distance Measures are used in many applications (e.g. clustering, classification, word modeling...) to measure how two objects are similar/different\n",
    "\n",
    "\n",
    "- Depending on the applications, datapoints can be web pages, movies, users, words, concepts...\n",
    "\n",
    "\n",
    "- Distances/Similarities are described by a single scalar, whose value is dependent on three factors:\n",
    "    - the properties of the **objects** \n",
    "    - the **coding** scheme choose to describe the objects\n",
    "    - the properites of the **measure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be qualifies as a **METRIC**, as distance/similarity measure must satisfy the following four conditions:\n",
    "\n",
    "- the distance between any points is always **nonegative**\n",
    "\n",
    "\n",
    "- the distance between two points equals $0$ iif two objects are **identical**\n",
    "\n",
    "\n",
    "- it is **symmetric**, i.e. $d(x,y) = d(y,x)$\n",
    "\n",
    "\n",
    "- **triangle inequality** must be satisfied, i.e. $d(x, z) \\leq d(x, y) + d(y, z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kNN algorithm is traditionally based on the use of traditional **statistical similarity measures**, where SMs are used to estimate the similarity between users (user-to-user kNN) or between items (item-to-item kNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the years, many RS-tailored measures have been proposed. In most cases, the use of these SMs lead to superior performances, even if:\n",
    "\n",
    "- some of these measures need information that is available only in certain architectures (e.g. social information)\n",
    "\n",
    "\n",
    "- some of them have not been extensively tested (and understood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Some) Statistical Similarity Measures\n",
    "\n",
    "- The traditional similarity measures, widely used also outside of the RS literature (e.g. clustering, ML, retrieving applications, DSMs...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EUCLIDEAN SIMILARITY**\n",
    "\n",
    "- euclidean distance is the ordinary straight-line distance between two points\n",
    "\n",
    "\n",
    "- distance is calculated by using the Pythagorean theorem\n",
    "\n",
    "\n",
    "- distance can be transformed into a similarity measure by summing 1 to the distance and inverting it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$sim_{\\ euclidean} (p,q)=\\frac{1}{dist(p,q)} = \\frac{1}{1 + \\sqrt{\\sum_{i = 1}^n (p_i - q_i)^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_similarity(p, q):\n",
    "    dist = math.sqrt(sum((pi-qi)**2 for pi,qi in zip(p, q)))\n",
    "    sim = 1 / (1+dist)\n",
    "    return sim    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**MANHATTAN SIMILARITY**\n",
    "\n",
    "- the Manhattan (a.k.a. taxicab, cityblock, rectilinear, $L_1$) distance between two points is calculated as the sum of the absolute distances of their Cartesian coordinates\n",
    "\n",
    "\n",
    "- similar to euclidean distance, but less influenced by outliers (i.e. by unusual values)\n",
    "\n",
    "    - in practice, you obtain similar results most of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$sim_{\\ manhattan} (p,q) =\\frac{1}{dist(p,q)} = \\frac{1}{1 + \\sum_{i = 1}^n |p_i - q_i|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:left;margin:0 25px 10px 20px\">\n",
    "    <img src=\"images/your_turn.jpg\" width=\"110\">\n",
    "</div>\n",
    "\n",
    "#### Your Turn.\n",
    "\n",
    "Write a function called `manhattan_similarity()` that calculates this metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def euclidean_similarity(p, q):\n",
    "    dist = sum(abs(pi-qi) for pi,qi in zip(p, q))\n",
    "    sim = 1 / (1+dist)\n",
    "    return sim    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COSINE SIMILARITY**\n",
    "\n",
    "- the normalized dot product of two vectors, i.e. the cosine of the angle between them\n",
    "\n",
    "\n",
    "- **scale-invariance**: cosine similarity is independent of vector length \n",
    "    - you can multiply your vector for any non-zero constant and the angle won't change\n",
    "    - it should be used when vector length is irrelevant\n",
    "    - in kNN, this means that it is independent of the absolute number of rating per user/item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$sim_{\\ cosine} (\\vec{p},\\vec{q})=\\frac{\\vec{p} \\cdot \\vec{q}}{\\lVert \\vec{p} \\rVert \\lVert \\vec{q} \\rVert} = \\frac{\\sum_{i = 1}^n p_i q_i}{\\sqrt{\\sum_{i = 1}^n (p_i)^2} \\sqrt{\\sum_{i = 1}^n (q_i)^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(p,q):\n",
    "    d = sum(pi * qi for pi,qi in zip(p, q))\n",
    "    mag_p = math.sqrt(sum([pi**2 for pi in p]))\n",
    "    mag_q = math.sqrt(sum([qi**2 for qi in q]))\n",
    "    sim = d / ( mag_p * mag_q)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PEARSON CORRELATION**: \n",
    "\n",
    "\n",
    "- measure of the strength of linear dependence between two variables\n",
    "\n",
    "\n",
    "- calculated as the ratio between the variance that is shared between the two variables (covariance) and the product of their standard deviations (i.e. of their variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$r(p,q) = \\frac{\\sum_{i = 1}^n (p_i - \\bar{p})(q_i - \\bar{q})}{\\sqrt{\\sum_{i = 1}^n (p_i - \\bar{p})^2}\\ \\sqrt{\\sum_{i = 1}^n (q_i - \\bar{q})^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the correlation value between two variables is invariant to **scale** and **location** tranformations:\n",
    "    - that is, if $a$, $b$, $c$, $d$ are constants and $a > 0$ and $c > 0$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$r(p,q) = r(a\\cdot p + b, c\\cdot q + d)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pearson_correlation(p,q):\n",
    "    # this code does not scale properly. In the following example we rely on \n",
    "    # scipy.spatial.distance.correlation() to compute long vectors\n",
    "    if len(p) > 99:\n",
    "        return 1 - distance.correlation(p,q)        \n",
    "    \n",
    "    p_mean = sum(p) / len(p)\n",
    "    p_deviations = [(pi-p_mean) for pi in p]\n",
    "    \n",
    "    q_mean = sum(q) / len(q)\n",
    "    q_deviations = [(qi-q_mean) for qi in q]\n",
    "    \n",
    "    cov = sum(pd * qd for pd,qd in zip(p_deviations, q_deviations))\n",
    "        \n",
    "    sds_product = math.sqrt(sum((pd)**2 for pd in p_deviations) * sum((qd)**2 for qd in q_deviations))\n",
    "    \n",
    "    if sds_product != 0:\n",
    "        r = cov / sds_product\n",
    "    else:\n",
    "        r = 0\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pearson correlation** and **cosine similarity**:\n",
    "\n",
    "- the pearson correlation is equivalent to the cosine similarity in which the values of the vectors has been **normalized to their arithmetic means**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$sim_{\\ cosine} (p - \\bar{p}, q - \\bar{q}) = \\frac{\\sum_{i = 1}^n (p_i - \\bar{p})(q_i - \\bar{q})}{\\sqrt{\\sum_{i = 1}^n (p_i - \\bar{p})^2}\\ \\sqrt{\\sum_{i = 1}^n (q_i - \\bar{q})^2}} = r(p,q) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- that is, the Pearson correlation and the cosine similarity are equivalent when the two vectors have **means of 0**\n",
    "\n",
    "    - geometrically, the pearson correlation can be seen as the angle between the two vectors where the origin of the coordinate system is translated at the arithmetic mean values of the vectors\n",
    "    - pearson correlation can be taught as as demeaned version of the cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JACCARD SIMILARITY** \n",
    "\n",
    "- a.k.a. **Tanimoto Coefficient**\n",
    "\n",
    "\n",
    "- similarity is measured as the ratio of the cardinality of the intersection set (number of items that are in both sets) to that of the union set (number of items in either sets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$sim_{\\ jaccard} (P, Q) = \\frac{|P \\cap Q|}{|P \\cup Q|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_sets(p,q): \n",
    "    intersection_cardinality = len(set(p).intersection(set(q)))\n",
    "    union_cardinality = len(set(p).union(set(q)))\n",
    "    sim = intersection_cardinality / union_cardinality\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- it is particularly useful  for **datasets with binary values** (e.g. 1s for a preference and 0s for indifference)\n",
    "    - in these cases, you have two objects $P$ and $Q$ with $n$ attributes...\n",
    "    - ... and you may use this measure to estimate the **overlap that $P$ and $Q$ share with their attributes**\n",
    "\n",
    "\n",
    "\n",
    "- if $M_{11}$ represents the number of attributes where both objects have a value of 1 and $M_{10} + M_{01}$ represents the number of attributes where only one object has a value of 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$sim_{\\ jaccard} = \\frac{M_{11}}{M_{01} + M_{10} + M_{11}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_binary(p, q):\n",
    "    \"\"\"\n",
    "    this is equivalent to the tanimoto() function by Segaran (2007:47) \n",
    "    \"\"\"\n",
    "    m_11, m_01, m_10 = 0, 0, 0\n",
    "    for pi, qi in zip(p, q):\n",
    "\n",
    "        if pi == 1:\n",
    "            if qi == 1:\n",
    "                m_11 += 1\n",
    "            else:\n",
    "                m_10 += 1\n",
    "                \n",
    "        elif qi == 1:\n",
    "            m_01 += 1\n",
    "    \n",
    "    sim = m_11 / (m_10 + m_01 + m_11) \n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:left;margin:0 25px 10px 20px\">\n",
    "    <img src=\"images/your_turn.jpg\" width=\"110\">\n",
    "</div>\n",
    "\n",
    "#### Your Turn.\n",
    "\n",
    "Given the following binary vectors, find a way to use `jaccard_sets()` to obtain `jaccard_binary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = [1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n",
    "q = [1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "jaccard_sets(p,q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which one Should I use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That really depends on your application:\n",
    "\n",
    "- how are we modeling our problem (i.e. are we using binary features)?\n",
    "\n",
    "\n",
    "- how do we want our measure to behave?\n",
    "    - do we want to be less sensistive to outliers?\n",
    "    - do we want it to be scale-invariat?\n",
    "    - do we want it to be location-invariat?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway, as a **rule of thumb**, the best practice is to try how the main similarity measures behave and decide on the basis of this empirical evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user-to-user kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an active user *a*:\n",
    "- use  a similarity measure to determine the *k* most-similar users to *a*\n",
    "\n",
    "\n",
    "- obtain the prediction on item *i* for user *a* by using one of the following aggregation approaches on the ratings from the neighborhood:\n",
    "    - average\n",
    "    - weighted sum\n",
    "    - adjusted weighted aggregation (deviation-from-mean)\n",
    "    \n",
    "    \n",
    "- choose the top-*n* items by selecting the *né items with the highest scores calculated by applying the previous steps on the items that haven’t been rated by the user *a*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: finding the top-50 similar users\n",
    "\n",
    "Let's build the neighborhood for our target user `4447` by calculating his similarity with the other raters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_similarity(ratings, id1, id2, measure, threshold = 0):\n",
    "    # get the list of shared rated items\n",
    "    shared = sorted(set(ratings[id1].keys()).intersection(set(ratings[id2].keys())))\n",
    "\n",
    "    # ignore comparisons with too few overlapping ratings (default is 0)\n",
    "    if len(shared) <= threshold:\n",
    "        return 0\n",
    "    \n",
    "    sel_ratings = [np.asarray([v for (k,v) in ratings[i].items() if k in shared]) for i in [id1, id2]]\n",
    "    \n",
    "    # compute similarity\n",
    "    sim = measure(*sel_ratings)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's calculate the similarities by using both the euclidean similarity and correlation (DURATION: 56 seconds)\n",
    "measure2function = {\"euclidean\" : euclidean_similarity, \"cosine\": cosine_similarity, \"correlation\": pearson_correlation}\n",
    "\n",
    "similarities = dict()\n",
    "for measure, function in measure2function.items():\n",
    "    similarities[measure] = dict()\n",
    "    for id1, id2 in product([4447], user2movies_ratings.keys()):\n",
    "        # do not compare our target user with himself\n",
    "        if id1 == id2:\n",
    "            continue\n",
    "        similarities[measure][id2] = calculate_similarity(user2movies_ratings, id1, id2, function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the most similar users according to each measure\n",
    "neighborhood = dict()\n",
    "for measure in similarities.keys():\n",
    "    neighborhood[measure] = dict(sorted(similarities[measure].iteritems(), key = itemgetter(1), reverse = True)[:50])\n",
    "print neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: obtain the predictions for all the items of interest \n",
    "\n",
    "- in a real life scenario, we should obtain a predictions for all the items that were not rated by our user\n",
    "\n",
    "\n",
    "- in this example, we will get predictions for just our three target movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the following weighted score to aggregate our ratings:\n",
    " \n",
    "- take the votes of all other critics and multiply them by their similarity with our target user\n",
    "\n",
    "\n",
    "- sum these weihted votes for each item fo interest\n",
    "\n",
    "\n",
    "- in order to handle the sparseness of the dataset (no movie has been rated by all the users), divide this score by the sum of all the similarities for critics that reviewed that movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. see the example from Segaran (2007: 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/weighting-users.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictions(movieId, neighborhood, ratings):\n",
    "    weigthed_scores = []\n",
    "    similarities = []\n",
    "\n",
    "    for user, sim in neighborhood.iteritems():\n",
    "        if ratings[user].has_key(movieId):\n",
    "            weigthed_scores.append(sim * ratings[user][movieId])\n",
    "            similarities.append(sim)\n",
    "    \n",
    "    return sum(weigthed_scores) / sum(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recommendations = defaultdict(dict)\n",
    "\n",
    "for measure in similarities.keys():\n",
    "    for movie in target_movies:\n",
    "        recommendations[measure][movie] = getPredictions(movie, neighborhood[measure], user2movies_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: choose the top-items \n",
    "\n",
    "- in a real life scenario, you should choose the top-rated items and recommend them to the user\n",
    "\n",
    "\n",
    "- in this exercise, we will compare the **rating predictions** produced by our RC against those produced by our user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is the **ranking** preserved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"- original ratings:\"\n",
    "\n",
    "for movieID in target_ratings:\n",
    "    print id2movie[movieID], \"-->\", target_ratings[movieID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for measure in similarities.keys():\n",
    "    print \"-\", measure, \"ratings:\"\n",
    "    for movieID in target_ratings:\n",
    "        print id2movie[movieID], \"-->\", recommendations[measure][movieID]\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's calculate the **Mean Absolute Error** \n",
    "\n",
    "- the difference between the real ratings and those produced by the RS\n",
    "\n",
    "\n",
    "- i.e. if $\\hat{y}_i$ is the predicted value of the $i$-th sample, $y_i$ is the true value and $n$ is the sample size:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$MAE(y, \\hat{y}) = \\frac{1}{n} \\sum_{i = 0}^{n - 1} \\left| \\ y_i, \\hat{y_i}\\ \\right|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_ratings = [target_ratings[movieID] for movieID in target_ratings]\n",
    "\n",
    "for measure in similarities.keys():\n",
    "    print \"-\", measure, \"MAE:\",\n",
    "    predicted = [recommendations[measure][movieID] for movieID in target_ratings]\n",
    "    print mean_absolute_error(true_ratings, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:left;margin:0 25px 10px 20px\">\n",
    "    <img src=\"images/your_turn.jpg\" width=\"110\">\n",
    "</div>\n",
    "\n",
    "#### Your Turn.\n",
    "\n",
    "See what happens if:\n",
    "\n",
    "- we specify a minimum rating overlap threshold (say, 10) in the `calculate_similarity()` function\n",
    "\n",
    "\n",
    "- we change the size of the neighborhood (say, to 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## item-to-item kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Given an active user *a*:\n",
    "\n",
    "- for each item in the database, use a similarity measure to determine its *k* most-similar items\n",
    "\n",
    "\n",
    "- for each item *i* not rated by *a*, predict its rating on the basis of the *a*’s previous ratings of the items in the *i*'s neighborhood\n",
    "\n",
    "\n",
    "- choose the top-*n* items by selecting the *n* items with the highest scores calculated in the previous step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: finding the top-25 similar items\n",
    "\n",
    "re-arranging the ratings dictionary allows us to use the `calculate_distance()` function to calculate the item-based similarities as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's rearrange the dictionary of ratings \n",
    "\n",
    "movies2user_ratings = defaultdict(dict)\n",
    "\n",
    "for user, user_ratings in user2movies_ratings.iteritems():\n",
    "    for movie, rating in user_ratings.iteritems():\n",
    "        movies2user_ratings[movie][user] = rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up the process, we will ignore all those movies that has not been rated by at least 1500 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_movies2user_ratings = dict()\n",
    "for movie in movies2user_ratings.keys():\n",
    "    if len(movies2user_ratings[movie]) < 1500:\n",
    "        continue\n",
    "    else:\n",
    "        filtered_movies2user_ratings[movie] = movies2user_ratings[movie]\n",
    "\n",
    "print \"-\", len(movies2user_ratings) - len(filtered_movies2user_ratings), \"movies have been descarded\"\n",
    "print \"-\", len(filtered_movies2user_ratings), \"movies have been selected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's calculate the similarities by using only correlation (NOTE: this is very inefficient!)\n",
    "\n",
    "similarities = defaultdict(dict)\n",
    "for id1, id2 in combinations(filtered_movies2user_ratings.keys(), 2):\n",
    "    similarities[id1][id2] = calculate_similarity(movies2user_ratings, id1, id2, pearson_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the most similar items\n",
    "neighborhood = dict()\n",
    "for movie in similarities.keys():\n",
    "    neighborhood[movie] = dict(sorted(similarities[movie].iteritems(), key = itemgetter(1), reverse = True)[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:left;margin:0 25px 10px 20px\">\n",
    "    <img src=\"images/your_turn.jpg\" width=\"110\">\n",
    "</div>\n",
    "\n",
    "#### Your Turn.\n",
    "\n",
    "Choose a movie and explore its immediate neighborhood by printing its most similar movies and using MDS (multi Dimensional Scaling) to plot them in a 2-dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: obtain the predictions for all the items of interest \n",
    "\n",
    "For all the items that the user hasn't rated (here we restrict ourselves to our three target movies), the following weighted score is used to aggregate our ratings:\n",
    "\n",
    "- for each pair of items composed by one item rated by our user and one of our items of interest, we calculate a score by multiplying their pairwise similarity and the rating for the known movie\n",
    "\n",
    "\n",
    "- for each item of interest we sum all these scores\n",
    "\n",
    "\n",
    "- the score is normalized by diving this total by the total of the pairwise similarity scores involving a item of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. see the example from Segaran (2007: 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/weighting-item.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictionsForItems(userId, neighborhood, ratings):\n",
    "    weigthed_scores = []\n",
    "    similarities = []\n",
    "\n",
    "    for item, sim in neighborhood.iteritems():\n",
    "        if ratings[item].has_key(userId):\n",
    "            weigthed_scores.append(sim * ratings[item][userId])\n",
    "            similarities.append(sim)\n",
    "    \n",
    "    return sum(weigthed_scores) / sum(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recommendations = defaultdict(dict)\n",
    "\n",
    "for movie in target_movies:\n",
    "    recommendations[movie] = getPredictionsForItems(4447, neighborhood[movie], filtered_movies2user_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: choose the top-items \n",
    "\n",
    "- in a real life scenario, you should choose the top-rated items and recommend them to the user\n",
    "\n",
    "\n",
    "- in this exercise, we will compare the **rating predictions** produced by our RC against those produced by our user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is the **ranking** preserved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"- original ratings:\"\n",
    "\n",
    "for movieID in target_ratings:\n",
    "    print id2movie[movieID], \"-->\", target_ratings[movieID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"- predicted ratings:\"\n",
    "for movieID in target_ratings:\n",
    "    print id2movie[movieID], \"-->\", recommendations[movieID]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's calculate the **Mean Absolute Error** (i.e. the difference between the real ratings and those produced by the RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_ratings = [target_ratings[movieID] for movieID in target_ratings]\n",
    "predicted = [recommendations[movieID] for movieID in target_ratings]\n",
    "\n",
    "print \"- MAE:\", mean_absolute_error(true_ratings, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### For Next Tuesday:\n",
    ">\n",
    "> - Read **Sections 14.1, 14.2 and 14.4** of Zhai C. X. & S. Massung (2016) Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining, Association for Computing Machinery and Morgan & Claypool\n",
    ">\n",
    ">\n",
    "> - Read Blei, D. M. (2012) Probabilistic Topic Models. In *Communications of the ACM*, 55 (4), pp. 77 - 84\n",
    ">\n",
    ">\n",
    "> - Prepare two questions about the topic of the lesson. Questions should be **sent by mail**, the subject line following the format: `“TMCI\\_questions\\_date-of-the-class\\_[YOUR LAST NAME]”` (e.g. `TCMI\\_questions_26/Sep\\_Lebani`)\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ignore what follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export this notebook as a HTML file\n",
    "# !jupyter nbconvert TMCI-2017-w9a --output html_converted_notebooks/TMCI-2017-w9a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
