{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:left;margin:5px 10px 5px 10px\" markdown=\"1\">\n",
    "    <img src=\"images/auc.png\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "<div style=\"float:right;margin-top:10px\" markdown=\"1\">\n",
    "    <h3><i>Text Mining & Collective Intelligence</i></h3>\n",
    "</div>\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "<center><h1>Making Recommendations</h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "<h3>by Gianluca E. Lebani</h3>\n",
    "<h4>• 31 Oct. 2017 •</h4>\n",
    "\n",
    "</center>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Today\n",
    ">\n",
    ">- [the MovieLens 1M Dataset](#the-MovieLens-1M-Dataset)\n",
    ">\n",
    ">\n",
    ">- [user-to-user kNN](#user-to-user-kNN)\n",
    ">\n",
    ">\n",
    ">- [item-to-item kNN](#item-to-item-kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from itertools import product, combinations\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the MovieLens 1M Dataset\n",
    "\n",
    "The MovieLens 1M dataset has been developed by the members of the [GroupLens](https://grouplens.org/) lab in the Department of Computer Science and Engineering at the University of Minnesota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MovieLens 1M dataset in brief:\n",
    "\n",
    "- Ratings: 1 million\n",
    "- Users: 6040\n",
    "- Rated Movies: 3592\n",
    "- Rated Scale: {1, ... , 5}\n",
    "- Additional information on the users: gender, age range, occupation, zip-code\n",
    "- Additional infomation on the movies: genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A zipped version of this dataset should be available in the `./data` folder, in case not [download it](https://grouplens.org/datasets/movielens/1m/) and unzip it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is composed by three files:\n",
    "\n",
    "- `movies.dat`, providing information about the rated movies \n",
    "    - it follows the format `MovieID::Title::Genres`\n",
    "    \n",
    "\n",
    "- `users.dat`, providing information about the users\n",
    "    - it follows the format `UserID::Gender::Age::Occupation::Zip-code`\n",
    "    - each user has at least 20 ratings\n",
    "\n",
    "\n",
    "- `ratings.dat`, encoding the ratings\n",
    "    - it follows the format `UserID::MovieID::Rating::Timestamp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/ml-1m/movies.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a6063b3e98a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mid2movie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/ml-1m/movies.dat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmovieId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"::\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/ml-1m/movies.dat'"
     ]
    }
   ],
   "source": [
    "id2movie = dict()\n",
    "\n",
    "with open(\"data/ml-1m/movies.dat\", \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        movieId, movie, _ = line.split(\"::\")\n",
    "        id2movie[int(movieId)] = movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user2movies_ratings = defaultdict(dict)\n",
    "\n",
    "with open(\"data/ml-1m/ratings.dat\", \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        userId, movieId, rating = [int(el) for el in line.split(\"::\")[:3]]\n",
    "        user2movies_ratings[userId][movieId] = rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:left;margin:0 25px 10px 20px\">\n",
    "    <img src=\"images/your_turn.jpg\" width=\"110\">\n",
    "</div>\n",
    "\n",
    "#### Your Turn.\n",
    "\n",
    "Explore the dataset:\n",
    "\n",
    "- what is the average rating?\n",
    "\n",
    "\n",
    "- which are the top-rated movies? And which are the lowest-rated ones?\n",
    "\n",
    "\n",
    "- what are the average ratings for men and women?\n",
    "\n",
    "\n",
    "- which movies received the highest rates from men? Which ones from women?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case\n",
    "\n",
    "In the following exercise we will try to model the rating:\n",
    "\n",
    "- given by subject  `4447`\n",
    "    - he gave 982 ratings\n",
    "\n",
    "\n",
    "- for the movies:\n",
    "\n",
    "    - `Back to the Future (1985)`: id = `1270`\n",
    "    - `Silence of the Lambs, The (1991)` : id = `593`\n",
    "    - `Raiders of the Lost Ark (1981)` : id = `1198`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_movies = [593, 1198, 1270]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's remove our target ratings from the dataset\n",
    "\n",
    "target_ratings = dict([(i, user2movies_ratings[4447].pop(i)) for i in target_movies])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user-to-user kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an active user *a*:\n",
    "- use  a similarity measure to determine the *k* most-similar users to *a*\n",
    "\n",
    "\n",
    "- obtain the prediction on item *i* for user *a* by using one of the following aggregation approaches on the ratings from the neighborhood:\n",
    "    - average\n",
    "    - weighted sum\n",
    "    - adjusted weighted aggregation (deviation-from-mean)\n",
    "    \n",
    "    \n",
    "- choose the top-*n* items by selecting the *né items with the highest scores calculated by applying the previous steps on the items that haven’t been rated by the user *a*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: finding the top-50 similar users\n",
    "\n",
    "Let's build the neighborhood for our target user `4447` by calculating his similarity with the other raters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_similarity(ratings, id1, id2, measure, threshold = 0):\n",
    "    # get the list of shared rated items\n",
    "    shared = sorted(set(ratings[id1].keys()).intersection(set(ratings[id2].keys())))\n",
    "\n",
    "    # ignore comparisons with too few overlapping ratings (default is 0)\n",
    "    if len(shared) <= threshold:\n",
    "        return 0\n",
    "    \n",
    "    sel_ratings = [[v for (k,v) in ratings[i].items() if k in shared] for i in [id1, id2]]\n",
    "    \n",
    "    # compute distance\n",
    "    distance = measure(*sel_ratings)\n",
    "    \n",
    "    # transform distance into a similarity score\n",
    "    if measure == distance.euclidean:\n",
    "        return 1 / (1 + distance)\n",
    "    else:\n",
    "        return 1 - distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's calculate the similarities by using both the euclidean similarity and correlation \n",
    "measure2function = {\"euclidean\" : distance.euclidean, \"correlation\" : distance.correlation}\n",
    "\n",
    "similarities = dict()\n",
    "for measure, function in measure2function.items():\n",
    "    similarities[measure] = dict()\n",
    "    for id1, id2 in product([4447], user2movies_ratings.keys()):\n",
    "        # do not compare our target user with himself\n",
    "        if id1 == id2:\n",
    "            continue\n",
    "        similarities[measure][id2] = calculate_distance(user2movies_ratings, id1, id2, function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the most similar users according to each measure\n",
    "neighborhood = dict()\n",
    "for measure in similarities.keys():\n",
    "    neighborhood[measure] = dict(sorted(similarities[measure].iteritems(), key = itemgetter(1), reverse = True)[:50])\n",
    "print neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: obtain the predictions for all the items of interest \n",
    "\n",
    "- in a real life scenario, we should obtain a predictions for all the items that were not rated by our user\n",
    "\n",
    "\n",
    "- in this example, we will get predictions for just our three target movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the following weighted score to aggregate our ratings:\n",
    " \n",
    "- take the votes of all other critics and multiply them by their similarity with our target user\n",
    "\n",
    "\n",
    "- sum these weihted votes for each item fo interest\n",
    "\n",
    "\n",
    "- in order to handle the sparseness of the dataset (no movie has been rated by all the users), divide this score by the sum of all the similarities for critics that reviewed that movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. see the example from Segaran (2007: 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/weighting-users.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictions(movieId, neighborhood, ratings):\n",
    "    weigthed_scores = []\n",
    "    similarities = []\n",
    "\n",
    "    for user, sim in neighborhood.iteritems():\n",
    "        if ratings[user].has_key(movieId):\n",
    "            weigthed_scores.append(sim * ratings[user][movieId])\n",
    "            similarities.append(sim)\n",
    "    \n",
    "    return sum(weigthed_scores) / sum(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recommendations = defaultdict(dict)\n",
    "\n",
    "for measure in similarities.keys():\n",
    "    for movie in target_movies:\n",
    "        recommendations[measure][movie] = getPredictions(movie, neighborhood[measure], user2movies_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: choose the top-items \n",
    "\n",
    "- in a real life scenario, you should choose the top-rated items and recommend them to the user\n",
    "\n",
    "\n",
    "- in this exercise, we will compare the **rating predictions** produced by our RC against those produced by our user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is the **ranking** preserved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"- original ratings:\"\n",
    "\n",
    "for movieID in target_ratings:\n",
    "    print id2movie[movieID], \"-->\", target_ratings[movieID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for measure in similarities.keys():\n",
    "    print \"-\", measure, \"ratings:\"\n",
    "    for movieID in target_ratings:\n",
    "        print id2movie[movieID], \"-->\", recommendations[measure][movieID]\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's calculate the **Mean Absolute Error** (i.e. the difference between the real ratings and those produced by the RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_ratings = [target_ratings[movieID] for movieID in target_ratings]\n",
    "\n",
    "for measure in similarities.keys():\n",
    "    print \"-\", measure, \"MAE:\",\n",
    "    predicted = [recommendations[measure][movieID] for movieID in target_ratings]\n",
    "    print mean_absolute_error(true_ratings, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:left;margin:0 25px 10px 20px\">\n",
    "    <img src=\"images/your_turn.jpg\" width=\"110\">\n",
    "</div>\n",
    "\n",
    "#### Your Turn.\n",
    "\n",
    "See what happens if:\n",
    "\n",
    "- we specify a minimum rating overlap threshold (say, 10) in the `calculate_similarity()` function\n",
    "\n",
    "\n",
    "- we change the size of the neighborhood (say, to 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## item-to-item kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Given an active user *a*:\n",
    "\n",
    "- for each item in the database, use a similarity measure to determine its *k* most-similar items\n",
    "\n",
    "\n",
    "- for each item *i* not rated by *a*, predict its rating on the basis of the *a*’s previous ratings of the items in the *i*'s neighborhood\n",
    "\n",
    "\n",
    "- choose the top-*n* items by selecting the *n* items with the highest scores calculated in the previous step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: finding the top-25 similar items\n",
    "\n",
    "re-arranging the ratings dictionary allows us to use the `calculate_distance()` function to calculate the item-based similarities as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's rearrange the dictionary of ratings \n",
    "\n",
    "movies2user_ratings = defaultdict(dict)\n",
    "\n",
    "for user, user_ratings in user2movies_ratings.iteritems():\n",
    "    for movie, rating in user_ratings.iteritems():\n",
    "        movies2user_ratings[movie][user] = rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up the process, we will ignore all those movies that has not been rated by at least 1500 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_movies2user_ratings = dict()\n",
    "for movie in movies2user_ratings.keys():\n",
    "    if len(movies2user_ratings[movie]) < 1500:\n",
    "        continue\n",
    "    else:\n",
    "        filtered_movies2user_ratings[movie] = movies2user_ratings[movie]\n",
    "\n",
    "print \"-\", len(movies2user_ratings) - len(filtered_movies2user_ratings), \"movies have been descarded\"\n",
    "print \"-\", len(filtered_movies2user_ratings), \"movies have been selected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's calculate the similarities by using only correlation (NOTE: this is very inefficient!)\n",
    "\n",
    "similarities = defaultdict(dict)\n",
    "for id1, id2 in combinations(filtered_movies2user_ratings.keys(), 2):\n",
    "    similarities[id1][id2] = calculate_distance(movies2user_ratings, id1, id2, distance.correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the most similar items\n",
    "neighborhood = dict()\n",
    "for movie in similarities.keys():\n",
    "    neighborhood[movie] = dict(sorted(similarities[movie].iteritems(), key = itemgetter(1), reverse = True)[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: obtain the predictions for all the items of interest \n",
    "\n",
    "For all the items that the user hasn't rated (here we restrict ourselves to our three target movies), the following weighted score is used to aggregate our ratings:\n",
    "\n",
    "- for each pair of items composed by one item rated by our user and one of our items of interest, we calculate a score by multiplying their pairwise similarity and the rating for the known movie\n",
    "\n",
    "\n",
    "- for each item of interest we sum all these scores\n",
    "\n",
    "\n",
    "- the score is normalized by diving this total by the total of the pairwise similarity scores involving a item of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. see the example from Segaran (2007: 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/weighting-item.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictionsForItems(userId, neighborhood, ratings):\n",
    "    weigthed_scores = []\n",
    "    similarities = []\n",
    "\n",
    "    for item, sim in neighborhood.iteritems():\n",
    "        if ratings[item].has_key(userId):\n",
    "            weigthed_scores.append(sim * ratings[item][userId])\n",
    "            similarities.append(sim)\n",
    "    \n",
    "    return sum(weigthed_scores) / sum(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recommendations = defaultdict(dict)\n",
    "\n",
    "for movie in target_movies:\n",
    "    recommendations[movie] = getPredictionsForItems(4447, neighborhood[movie], filtered_movies2user_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: choose the top-items \n",
    "\n",
    "- in a real life scenario, you should choose the top-rated items and recommend them to the user\n",
    "\n",
    "\n",
    "- in this exercise, we will compare the **rating predictions** produced by our RC against those produced by our user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is the **ranking** preserved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"- original ratings:\"\n",
    "\n",
    "for movieID in target_ratings:\n",
    "    print id2movie[movieID], \"-->\", target_ratings[movieID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"- predicted ratings:\"\n",
    "for movieID in target_ratings:\n",
    "    print id2movie[movieID], \"-->\", recommendations[movieID]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's calculate the **Mean Absolute Error** (i.e. the difference between the real ratings and those produced by the RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_ratings = [target_ratings[movieID] for movieID in target_ratings]\n",
    "predicted = [recommendations[movieID] for movieID in target_ratings]\n",
    "\n",
    "print \"- MAE:\", mean_absolute_error(true_ratings, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ignore what follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export this notebook as a HTML file\n",
    "# !jupyter nbconvert TMCI-2017-w9a --output html_converted_notebooks/TMCI-2017-w9a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
